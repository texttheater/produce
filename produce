#!/usr/bin/env python3

import argparse
import errno
import logging
import os
import re
import shlex
import subprocess
import sys
import time

from collections import OrderedDict
from configparser import ConfigParser

### PLANNED FEATURES

# TODO variation on the file rule type that unconditionally runs the recipe
# but with a temp file with target, then percolates dirtiness only if the new
# file differs from the existing version - e.g. for files that depend on data
# from a database.
# TODO dependency globbing using Python expressions that evaluate to sequences,
# wrapped in %@{...}
# TODO flat producing: run the recipe of the target, touch all existing
# dependencies
# TODO optionally delete intermediate files
# TODO attribute that automatically tees STDERR (possibly also STDOUT) of a
# recipe into a logfile corresponding to the target, e.g. %{target}.log

### UTILITIES

def dedup(seq):
    """Deduplicates a sequence - courtesy of
    http://www.peterbe.com/plog/uniqifiers-benchmark"""
    seen = set()
    seen_add = seen.add
    return [x for x in seq if not x in seen and not seen_add(x)]

def mtime(path, default=0):
    """Returns the mtime of the file at the specified path. Returns default if
    file does not exist. An OSError is raised if the file cannot be stat'd."""
    try:
        return os.stat(path).st_mtime
    except OSError as e:
        if e.errno == errno.ENOENT:
            return default
        raise e

def now():
    return time.time()

### ERRORS

class ProduceError(Exception):

    def __init__(self, message, cause=None):
        Exception.__init__(self, message)
        self.cause = cause

### COMMANDLINE PROCESSING

def process_commandline():
    parser = argparse.ArgumentParser()
    parser.add_argument('-B', '--always-build', action='store_true',
            help="""unconditionally build all targets""")
    parser.add_argument('-f', '--file', default='produce.ini',
            help="""use FILE as a producefile""")
    parser.add_argument('-n', '--dry-run', action='store_true', help="""print
            the commands that would be executed, but do not execute them""")
    parser.add_argument('-d', '--debug', action='store_true', help="""print
            debugging information""")
    parser.add_argument('target', nargs='*', help="""the target(s) to produce
            - if omitted, default target from producefile is used""")
    return parser.parse_args()

### PRODUCEFILE PARSING

def preprocess_producefile(f):
    for line in f:
        if line.startswith('[]'):
            yield '[%GLOBALS]' + line[2:]
        elif line.startswith('[%GLOBALS]'):
            raise ProduceError('illegal section name %GLOBALS')
        else:
            yield line

### PATTERN MATCHING AND INTERPOLATION

def interpolate(string, globes, lokes, ignore_undefined=False,
        keep_escaped=False):
    logging.debug('interpolate called with lokes: %s', lokes)
    original_string = string
    result = ''
    while string:
        if string.startswith('%%'):
            if keep_escaped:
                result += '%%'
            else:
                result += '%'
            string = string[2:]
        elif string.startswith('%{') and '}' in string:
            # TODO check that the part between curly braces is a valid
            # Python expression
            # TODO Make it possible for the Python expression to contain }.
            index = string.index('}')
            expression = string[2:index]
            try:
                try:
                    value = eval(expression, globes, lokes)
                except NameError as e:
                    raise e
                except Exception as e:
                    raise ProduceError(('{} evaluating expression {} in ' +
                            'pattern {}: {}').format(e.__class__.__name__,
                            expression, original_string, e))
                logging.debug('interpolating %s into %s', expression, value)
                result += str(value)
                string = string[index + 1:]
            except NameError:
                if ignore_undefined:
                    result += string[:index + 1]
                    string = string[index + 1:]
                else:
                    raise ProduceError(
                            'undefined variable "{}" in pattern "{}"'.format(
                            expression, original_string))
        elif string.startswith('%'):
            raise ProduceError('% must be followed by % or variable name in ' +
                    'curly braces in pattern {}'.format(original_string))
        else:
            result += string[:1]
            string = string[1:]
    return result

def section_name_to_regex(name, globes={}):
    if len(name) > 1 and name.startswith('/') and name.endswith('/'):
        try:
            return re.compile(name[1:-1])
        except Exception as e:
            raise ProduceError('{} in regex {}'.format(e, name))
    else:
        return produce_pattern_to_regex(name, globes)

def produce_pattern_to_regex(pattern, globes={}):
    # TODO distinguish syntactically between matchers and variable references?
    # Would allow to override global variables by matching.
    ip = interpolate(pattern, globes, {}, ignore_undefined=True,
            keep_escaped=True)
    regex = ''
    while ip:
        if ip.startswith('%%'):
            regex += '%'
            ip = ip[:2]
        # FIXME using the same variable twice in the pattern can be useful but
        # the re library will raise an exception
        elif ip.startswith('%{') and '}' in ip:
            # TODO check that the part between curly braces is a valid
            # Python identifier (or, eventually, expression)
            index = ip.index('}')
            variable = ip[2:index]
            regex += '(?P<' + variable + '>.*)'
            ip = ip[index + 1:]
        else:
            regex += re.escape(ip[:1])
            ip = ip[1:]
    regex += '$' # re.match doesn't enforce reaching the end by itself
    logging.debug('generated regex: %s', regex)
    return re.compile(regex)

### INSTANTIATED RULES

# An instantiated rules is represented by a dict that correspond to one rule
# section from the producefile, with the values already expanded. There are two
# special keys, target (the target as matched by the section header), and type,
# which must be one of file and task and defaults to file.

# TODO: Wrap these dictionaries, the following functions that operate on them
# as well as some of the dicts in Production into a Target class for a nicer
# abstraction.

def run_recipe(irule, dry_run=False):
    if not 'recipe' in irule:
        return
    target = irule['target']
    if irule.get('type', 'file') == 'task':
        logging.info('running task %s', target)
    else:
        if os.path.exists(target):
            logging.info('rebuilding file %s', target)
        else:
            logging.info('building file %s', target)
    recipe = irule['recipe']
    executable = 'bash' # TODO make configurable
    if recipe.startswith('\n'):
        recipe = recipe[1:]
    print(recipe) # TODO add --s --silent --quiet option
    if not dry_run:
        exit = subprocess.call(recipe, shell=True, executable=executable,
                stdin=sys.stdin)
        if exit != 0:
            # TODO delete target? Good for up-to-dateness, bad for debugging.
            raise ProduceError('recipe failed: {}'.format(recipe))
        # TODO check here if file was created for file rules, raise exception if not?

def create_irule(target, rules, globes):
    # Go through rules until a pattern matches the target:
    # TODO allow rules to impose additional constraints on their matching using a
    # "match" or "check" attribute.
    for pattern, avpairs in rules.items():
        match = pattern.match(target)
        if match:
            # Dictionary representing the instantiated rule:
            result = {}
            # Dictionary for local variables:
            # TODO is the empty string a good default?
            lokes = match.groupdict(default = '')
            # Special attribute: target
            result['target'] = target
            lokes['target'] = target
            # Process attributes and their values:
            for attribute, value in avpairs.items():
                # Remove prefix from attribute to get local variable name:
                loke = attribute.split('.')[-1]
                if loke == 'target':
                    raise ProduceError('cannot overwrite "target" attribute ' +
                            'in rule for {}'.format(target))
                # Do expansions in value:
                iv = interpolate(value, globes, lokes)
                # Attribute retains prefix:
                result[attribute] = iv
                # Local variable does not retain prefix:
                lokes[loke] = iv
            logging.debug('instantiated rule for target %s has lokes: %s',
                    target, lokes)
            result['type'] = result.get('type', 'file')
            if result['type'] not in ('file', 'task'):
                raise ProduceError('unknown type {} for target {}'.format(
                    target_type, target))
            return result
    if os.path.exists(target):
        # Although there is no rule to make the target, the target is a file
        # that exists, so we can use it as an ingredient.
        return {'target': target, 'type': 'file'}
    raise ProduceError('no rule to produce {}.'.format(target))

def list_ddeps(irule):
    result = []
    for key, value in irule.items():
        if key.startswith('dep.'):
            result.append(value)
        elif key == 'deps':
            result.extend(shlex.split(value))
    return result

### PRODUCTION

class Production:

    """
    An object of this class represents one run of produce. The methods are the
    building blocks of the algorithm, the attributes represent options and
    state that changes during the production process.
    """

    def __init__(self, targets, rules, globes, dry_run, always_build):
        # General properties, passed as arguments to constructor:
        self.rules = rules # maps patterns to key-uninstantiated value maps ("rules")
        self.globes = globes
        self.dry_run = dry_run
        self.always_build = always_build
        # Initialize fields to store information about individual targets:
        self.targets = []
        self.target_irule = {} # maps targets to key-instantiated value maps ("instantiated rules")
        self.target_ddeps = {} # direct dependencies
        self.target_time = {}
        self.out_of_date_targets = set()
        self.missing_targets = set()
        # Now fill them:
        for target in targets:
            self.add_target(target, [])

    def add_target(self, target, beam):
        # Catch cyclic dependencies:
        if target in beam:
            raise ProduceError('cyclic dependency: {}'.format(' -> '.join(beam)
                    ))
        # Stop on encountering a target for the second time:
        if target in self.targets:
            return
        # Make instantiated rule:
        irule = create_irule(target, self.rules, self.globes)
        # Determine dependencies and add them recursively:
        ddeps = list_ddeps(irule)
        logging.debug('direct dependencies of %s: %s', target, ddeps)
        for ddep in ddeps:
            self.add_target(ddep, beam + [target])
        # Determine type, existence and time of target:
        target_type = irule['type']
        if target_type == 'task':
            missing = False
            time = 0
        else:
            missing = not os.path.exists(target)
            if missing:
                time = 0
            else:
                time = mtime(target, 0)
        # Determine whether target is out of date, based on information about
        # dependencies, all of which are at this point guaranteed to have been
        # added:
        # 1. Tasks are always considered out of date.
        # 2. If any dependency is newer than the target, the target is out of
        #    date.
        # 3. If any dependency is out of date, so is the target.
        # 4. Consider it out of date if the always_build option is True.
        out_of_date = target_type == 'task' \
                or (ddeps \
                and max([self.target_time[ddep] for ddep in ddeps]) > time) \
                or any([self.is_out_of_date(ddep) for ddep in ddeps]) \
                or self.always_build
        logging.debug('%s out of date? %s', target, out_of_date)
        # Store information about this target:
        self.targets.append(target)
        self.target_irule[target] = irule
        self.target_ddeps[target] = ddeps
        self.target_time[target] = time
        if out_of_date:
            self.out_of_date_targets.add(target)
        if missing:
            self.missing_targets.add(target)

    def is_out_of_date(self, target):
        return target in self.out_of_date_targets

    def is_missing(self, target):
        return target in self.missing_targets

    def build(self, target):
        for ddep in self.target_ddeps[target]:
            self.build_if_required(ddep)
        run_recipe(self.target_irule[target], dry_run=self.dry_run)
        self.out_of_date_targets.discard(target)
        self.missing_targets.discard(target)

    def build_if_required(self, target):
        if not (self.is_out_of_date(target) or self.is_missing(target)):
            return False
        self.build(target)
        return True

    def produce(self, targets):
        if all([not self.build_if_required(target) for target in targets]):
            logging.info('all targets are up to date')

### MAIN

if __name__ == '__main__':
    args = process_commandline()
    if args.debug:
        level = logging.DEBUG
    else:
        level = logging.INFO
    logging.basicConfig(format='%(levelname)s: %(message)s',
            level=level)
    try:
        try:
            with open(args.file) as f:
               contents = ''.join(preprocess_producefile(f))
        except IOError as e:
            raise ProduceError('cannot read file {}'.format(args.file), e)
        # produce has its own mechanism for interpolation, switch ConfigParser's
        # off.
        # ConfigParser does not support having no default section. >:-(
        # Set default section name to something non-conflicting.
        parser = ConfigParser(default_section='%DEFAULT', interpolation=None)
        # Disable normalization, we want case-sensitive options:
        parser.optionxform = lambda x: x
        # Process config file:
        parser.read_string(contents)
        globes = OrderedDict() # "globals" is built-in
        if '%GLOBALS' in parser:
            for att, val in parser['%GLOBALS'].items():
                globes[att] = interpolate(val, globes, {})
        rules = OrderedDict()
        for section in parser:
            if section in ('%GLOBALS', '%DEFAULT'):
                continue
            # TODO in patterns, should we also expand locally defined
            # variables?
            rules[section_name_to_regex(section, globes=globes)] = \
                    OrderedDict(parser[section])
        # Produce:
        targets = args.target
        if not targets:
            if 'default' in globes:
                targets = [globes['default']]
            else:
                raise ProduceError('Don\'t know what to produce. Specify a ' +
                        'target on the command line or a default target in ' +
                        'produce.ini.')
        Production(targets, rules, globes, args.dry_run, args.always_build
                ).produce(targets)
    except ProduceError as e:
        logging.error(e) # TODO better formatting
        sys.exit(1)
    except KeyboardInterrupt as e:
        logging.error('Interrupted by user. Exiting.') # TODO cleanup?
        sys.exit(2)
